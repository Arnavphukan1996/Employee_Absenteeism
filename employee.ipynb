{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from math import sqrt\n",
    "from sklearn import metrics\n",
    "from numpy import cov\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/Arnav Phukan/Desktop/Projects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the directory is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Abs.xls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for uniqueness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Absenteeism time in hours'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datatypes of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing value analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "missing_val = pd.DataFrame(df.isnull().sum())\n",
    "missing_val = missing_val.reset_index()\n",
    "missing_val = missing_val.rename(columns = {'index':'variables',0:'Missing_Percentage'})\n",
    "missing_val['Missing_Percentage'] = (missing_val['Missing_Percentage']/len(df))*100\n",
    "print(missing_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing missing values with the help of median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Reason for absence'] = df['Reason for absence'].fillna(df['Reason for absence'].median())\n",
    "df['Month of absence'] = df['Month of absence'].fillna(df['Month of absence'].median())\n",
    "df['Transportation expense'] = df['Transportation expense'].fillna(df['Transportation expense'].median())\n",
    "df['Distance from Residence to Work'] = df['Distance from Residence to Work'].fillna(df['Distance from Residence to Work'].median())\n",
    "df['Service time'] = df['Service time'].fillna(df['Service time'].median())\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "df['Work load Average/day '] = df['Work load Average/day '].fillna(df['Work load Average/day '].median())\n",
    "df['Hit target'] = df['Hit target'].fillna(df['Hit target'].median())\n",
    "df['Disciplinary failure'] = df['Disciplinary failure'].fillna(df['Disciplinary failure'].median())\n",
    "df['Education'] = df['Education'].fillna(df['Education'].median())\n",
    "df['Social drinker'] = df['Social drinker'].fillna(df['Social drinker'].median())\n",
    "df['Social smoker'] = df['Social smoker'].fillna(df['Social smoker'].median())\n",
    "df['Son'] = df['Son'].fillna(df['Son'].median())\n",
    "df['Pet'] = df['Pet'].fillna(df['Pet'].median())\n",
    "df['Height'] = df['Height'].fillna(df['Height'].median())\n",
    "df['Weight'] = df['Weight'].fillna(df['Weight'].median())\n",
    "df['Body mass index'] = df['Body mass index'].fillna(df['Body mass index'].mean())\n",
    "df['Absenteeism time in hours'] =df['Absenteeism time in hours'].fillna(df['Absenteeism time in hours'].median())\n",
    "df.isnull().sum()\n",
    "data =df.copy()\n",
    "df['ID'] = df['ID'].astype('category')\n",
    "df['Reason for absence'] = df['Reason for absence'].astype('category')\n",
    "df['Month of absence'] = df['Month of absence'].astype('category')\n",
    "df['Day of the week'] = df['Day of the week'].astype('category')\n",
    "df['Seasons'] = df['Seasons'].astype('category')\n",
    "df['Disciplinary failure'] = df['Disciplinary failure'].astype('category')\n",
    "df['Education'] = df['Education'].astype('category')\n",
    "df['Social drinker'] = df['Social drinker'].astype('category')\n",
    "df['Social smoker'] = df['Social smoker'].astype('category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "plt.boxplot(df['Transportation expense'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df['Distance from Residence to Work'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df['Service time'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df['Age'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df['Work load Average/day '])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df['Hit target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df['Son'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df['Pet'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df['Weight'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df['Height'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df['Body mass index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df['Absenteeism time in hours'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df :\n",
    "    print(i)\n",
    "    q65,q35 = np.percentile(df.loc[:,i],[65,35])\n",
    "    iqr = q65 - q35\n",
    "    min = q35 - (iqr*1.5)\n",
    "    max = q65 + (iqr*1.5)\n",
    "    \n",
    "    print(min)\n",
    "    print(max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the min & max values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q65,q35 = np.percentile(df['Transportation expense'],[65,35])\n",
    "iqr = q65 - q35\n",
    "min1= q35 - (iqr*1.5)\n",
    "max1 = q65 + (iqr*1.5)\n",
    "print(min1)\n",
    "print(max1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q65,q35 = np.percentile(df['Age'],[65,35])\n",
    "iqr = q65 - q35\n",
    "min2 = q35 - (iqr*1.5)\n",
    "max2 = q65 + (iqr*1.5)\n",
    "print(min2)\n",
    "print(max2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q65,q35 = np.percentile(df['Service time'],[65,35])\n",
    "iqr = q65 - q35\n",
    "min3= q35 - (iqr*1.5)\n",
    "max3 = q65 + (iqr*1.5)\n",
    "print(min3)\n",
    "print(max3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q65,q25 = np.percentile(df['Work load Average/day '],[65,35])\n",
    "iqr = q65 - q35\n",
    "min4 = q35 - (iqr*1.5)\n",
    "max4 = q65 + (iqr*1.5)\n",
    "print(min4)\n",
    "print(max4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q65,q35 = np.percentile(df['Hit target'],[65,35])\n",
    "iqr = q65 - q35\n",
    "min5 = q35 - (iqr*1.5)\n",
    "max5 = q65 + (iqr*1.5)\n",
    "print(min5)\n",
    "print(max5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q65,q35 = np.percentile(df['Pet'],[65,35])\n",
    "iqr = q65 - q35\n",
    "min6 = q35 - (iqr*1.5)\n",
    "max6 = q65 + (iqr*1.5)\n",
    "print(min6)\n",
    "print(max6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q65,q35 = np.percentile(df['Height'],[65,35])\n",
    "iqr = q65 - q35\n",
    "min7 = q35 - (iqr*1.5)\n",
    "max7 = q65 + (iqr*1.5)\n",
    "print(min7)\n",
    "print(max7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing outliers values with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Transportation expense'] = df['Transportation expense'].fillna(df['Transportation expense'].median())\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "df['Work load Average/day '] = df['Work load Average/day '].fillna(df['Work load Average/day '].median())\n",
    "df['Hit target'] = df['Hit target'].fillna(df['Hit target'].median())\n",
    "df['Service time'] = df['Service time'].fillna(df['Service time'].median())\n",
    "df['Pet'] = df['Pet'].fillna(df['Pet'].median())\n",
    "df['Height'] = df['Height'].fillna(df['Height'].median())\n",
    "df['Absenteeism time in hours'] =df['Absenteeism time in hours'].fillna(df['Absenteeism time in hours'].median())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying data in new object \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ID'] = data['ID']\n",
    "df['Reason for absence'] = data['Reason for absence']\n",
    "df['Month of absence'] = data['Month of absence']\n",
    "df['Day of the week'] = data['Day of the week']\n",
    "df['Seasons'] = data['Seasons']\n",
    "df['Distance from Residence to Work'] = data['Distance from Residence to Work']\n",
    "df['Disciplinary failure'] = data['Disciplinary failure']\n",
    "df['Education'] = data['Education']\n",
    "df['Son'] = data['Son']\n",
    "df['Social drinker'] = data['Social drinker']\n",
    "df['Social smoker'] = data['Social smoker']\n",
    "df['Weight'] = data['Weight']\n",
    "df['Body mass index'] = data ['Body mass index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking missing values after outlier analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missval = pd.DataFrame(df.isnull().sum())\n",
    "print(missval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting data in proper data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ID'] = df['ID'].astype('category')\n",
    "df['Reason for absence'] = df['Reason for absence'].astype('category')\n",
    "df['Month of absence'] = df['Month of absence'].astype('category')\n",
    "df['Day of the week'] = df['Day of the week'].astype('category')\n",
    "df['Seasons'] = df['Seasons'].astype('category')\n",
    "df['Disciplinary failure'] = df['Disciplinary failure'].astype('category')\n",
    "df['Education'] = df['Education'].astype('category')\n",
    "df['Social drinker'] = df['Social drinker'].astype('category')\n",
    "df['Social smoker'] = df['Social smoker'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_c = df[['Transportation expense', 'Distance from Residence to Work', 'Service time', 'Age', 'Work load Average/day ', 'Hit target',\n",
    "     'Son', 'Pet', 'Weight', 'Height', 'Body mass index','Absenteeism time in hours']]\n",
    "print(numeric_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = numeric_c.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize = (12,8))\n",
    "sns.heatmap(corr,mask = np.zeros_like(corr,dtype = np.object),cmap = sns.diverging_palette(220,10,as_cmap = True),square = True, ax=ax,annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA for categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = df[['ID', 'Reason for absence', 'Month of absence', 'Day of the week','Seasons', 'Disciplinary failure', 'Education', 'Social drinker',\n",
    "       'Social smoker',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.f_oneway(df[\"Absenteeism time in hours\"],df[\"Reason for absence\"]))\n",
    "print(stats.f_oneway(df[\"Absenteeism time in hours\"],df[\"Month of absence\"]))\n",
    "print(stats.f_oneway(df[\"Absenteeism time in hours\"],df[\"Day of the week\"]))\n",
    "print(stats.f_oneway(df[\"Absenteeism time in hours\"],df[\"Seasons\"]))\n",
    "print(stats.f_oneway(df[\"Absenteeism time in hours\"],df[\"Disciplinary failure\"]))\n",
    "print(stats.f_oneway(df[\"Absenteeism time in hours\"],df[\"Education\"]))\n",
    "print(stats.f_oneway(df[\"Absenteeism time in hours\"],df[\"Social drinker\"]))\n",
    "print(stats.f_oneway(df[\"Absenteeism time in hours\"],df[\"Social smoker\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(['ID','Seasons','Education','Height','Hit target','Pet','Body mass index','Disciplinary failure','Age','Social smoker','Social drinker','Son'],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Transportation expense'].hist(bins = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Distance from Residence to Work'].hist(bins = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Service time'].hist(bins = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[ 'Work load Average/day '].hist(bins = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Weight'].hist(bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "normalized_df= preprocessing.normalize(df)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Algorithm\n",
    "### Dividing data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(df,test_size= 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "fit = DecisionTreeRegressor(max_depth = 2).fit(train.iloc[:,0:8],train.iloc[:,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dt = fit.predict(test.iloc[:,0:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_dt = (mean_squared_error(test.iloc[:,8], predictions_dt))\n",
    "print(mse_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_dt = sqrt(mean_squared_error(test.iloc[:,8],predictions_dt))\n",
    "print(rmse_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest\n",
    "### n=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "rfregressor200 = RandomForestRegressor(n_estimators = 200, random_state = 0)\n",
    "rfregressor200.fit(train.iloc[:,0:8],train.iloc[:,8])\n",
    "predictions_rf200 = rfregressor200.predict(test.iloc[:,0:8])\n",
    "mse_rf200 = (mean_squared_error(test.iloc[:,8], predictions_rf200))\n",
    "print(mse_rf200)\n",
    "rmse_rf200 = sqrt(mean_squared_error(test.iloc[:,8],predictions_rf200))\n",
    "print(rmse_rf200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "rfregressor300 = RandomForestRegressor(n_estimators = 300, random_state = 0)\n",
    "rfregressor300.fit(train.iloc[:,0:8],train.iloc[:,8])\n",
    "predictions_rf300 = rfregressor200.predict(test.iloc[:,0:8])\n",
    "mse_rf300 = (mean_squared_error(test.iloc[:,8], predictions_rf200))\n",
    "print(mse_rf300)\n",
    "rmse_rf300 = sqrt(mean_squared_error(test.iloc[:,8],predictions_rf300))\n",
    "print(rmse_rf300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n=400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "rfregressor400 = RandomForestRegressor(n_estimators = 400, random_state = 0)\n",
    "rfregressor400.fit(train.iloc[:,0:8],train.iloc[:,8])\n",
    "predictions_rf400 = rfregressor400.predict(test.iloc[:,0:8])\n",
    "mse_rf400 = (mean_squared_error(test.iloc[:,8], predictions_rf400))\n",
    "print(mse_rf400)\n",
    "rmse_rf400 = sqrt(mean_squared_error(test.iloc[:,8],predictions_rf400))\n",
    "print(rmse_rf400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
